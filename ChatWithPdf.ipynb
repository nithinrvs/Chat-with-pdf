{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtkCHk9cM25Z"
      },
      "source": [
        "# **Installing required packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "yxx5bPfdSTkI"
      },
      "outputs": [],
      "source": [
        "!pip install google-generativeai langchain PyPDF2 chromadb faiss-cpu langchain_google_genai langchain-community python-dotenv --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM24tCsmV1VG"
      },
      "source": [
        "# **Load Gemini api key**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm23mw4-V5sj"
      },
      "source": [
        "Save your gemini api key in a .env file in drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WF1kQsPoUm9w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "dotenv_path = '/content/drive/My Drive/.env'\n",
        "\n",
        "load_dotenv(dotenv_path)\n",
        "\n",
        "google_api_key = os.getenv('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SuuzJsgNHQS"
      },
      "source": [
        "# **Chat with pdf**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WfcqmeGIMyXu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import google.generativeai as genai\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7atQZNW0PB2t"
      },
      "outputs": [],
      "source": [
        "def read_pdf(file_path):\n",
        "    pdf_reader = PdfReader(file_path)\n",
        "\n",
        "    text = \"\"\n",
        "    for page in pdf_reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VOwerw7PfrY",
        "outputId": "782e6f70-65a3-41b3-946b-ae88b9423d91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "School of Computer Science and Engineering  \n",
            " \n",
            "Sentiment analysis for Telugu  Reviews  \n",
            "Project report s ubmitted to the partial fulfilment of the course  \n",
            "CSI4001 – Natural Language Processing and Computational Linguistics  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Project report dated :  30-04-2024  \n",
            "  \n",
            "   \n",
            "1. Project Objective  \n",
            " \n",
            "The objective of this project is to develop a sentiment analysis system for \n",
            "Telugu language,reviews of electronic products, categorizing them as positive \n",
            "(1) or negative (0) by analyzing Telugu user opinions.  \n",
            "The goal is to understand sentiment towards electronic products in their \n",
            "language, aiding in product enhancement for improved customer satisfaction. \n",
            "This involves NLP tasks such as tokenization, N -gram analysis for word \n",
            "sequences, utilizing BERT models for  contextual understanding, and word -to-\n",
            "vector conversion to process Telugu text effectively and using some machine \n",
            "learning techniques and ,GRU , bidirectional LSTM,LSTM as models to train \n",
            "the data on and check which is more accurate. Through these techniq ues, the \n",
            "system aims to provide insights crucial for optimizing products based on \n",
            "Telugu -speaking users' feedback.  \n",
            " \n",
            "2. Related works and Gap  \n",
            "The field of sentiment analysis, specially in languages with limited resources \n",
            "like Telugu, presents unique challenges due to the scarcity of annotated data, \n",
            "language -specific tools, and established research frameworks.  \n",
            " \n",
            "Existing work:  \n",
            "A two -phase sentiment analysis for Telugu news sentences using Telugu \n",
            "SentiWordNet. Initially, it identifies subjectivity classification, where each \n",
            "sentence is classified as subjective or objective. Objective sentences are \n",
            "treated as neutral sentiment as they don't carry any sentiment value. Next, \n",
            "sentiment classification is performed, where subjective sentences are further \n",
            "classified as positive or negative.This proposed system achieves an accuracy \n",
            "of 74% and 81% for subjectivity and sentiment classificat ion, respectively.  \n",
            " \n",
            "While sentiment analysis exists for Telugu text, current systems typically \n",
            "require English input, translating the meaning to Telugu for analysis. There's a \n",
            "lack of models that directly accept Telugu user prompts, making this project a \n",
            "novel approach in thi s area.  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "  \n",
            "Gaps Addressed:  \n",
            " \n",
            "Native Language Analysis:  This project focuses on analyzing Telugu \n",
            "reviews directly, eliminating the need for translation and making the process \n",
            "more user -friendly for Telugu speakers.  \n",
            "Deeper Product Insights:  By understanding sentiment in their native \n",
            "language, Telugu users can provide more refined feedback on electronic \n",
            "products. This allows companies to gain a deeper understanding of their \n",
            "Telugu customer base and tailor product improvements to their specifi c needs \n",
            "and preferences.  \n",
            "Increased Accessibility:  A Telugu sentiment analysis system empowers \n",
            "Telugu speakers who may not be proficient in English to participate in product \n",
            "reviews and have their voices heard. This can lead to a more inclusive \n",
            "product development process.  \n",
            " \n",
            " \n",
            "3. Proposed Solution to the Problem:  \n",
            " \n",
            "1.Methodology Overview:  The proposed solution involves leveraging Natural \n",
            "Language Processing (NLP) techniques and machine learning models to \n",
            "analyze and classify Telugu text reviews. Key tasks include tokenization, N -\n",
            "gram analysis, word embeddings, and model training using LSTM  (Long \n",
            "Short -Term Memory) networks.  \n",
            " \n",
            "2.Data collection:  The Sentiraama corpus is used for training data, which \n",
            "includes both positive and negative Telugu reviews.  \n",
            " \n",
            "3.Data Preprocessing:  The project begins with data preprocessing steps \n",
            "such as text cleaning, punctuation removal, tokenization, and padding to \n",
            "ensure uniform input sequences for the machine learning models.  \n",
            " \n",
            "4.Tokenization : \n",
            "Tokenization is employed to break down Telugu text into individual tokens, \n",
            "capturing the semantic meaning and linguistic structure of the reviews.  \n",
            " \n",
            " \n",
            " \n",
            "  \n",
            "5. , N -grams:  \n",
            "N-grams analysis, including unigrams, bigrams, and trigrams, is utilized to \n",
            "extract features that encompass both individual word context and broader \n",
            "contextual information within the reviews.  \n",
            " \n",
            "6.Text Embeddings:  \n",
            "Text embeddings are generated using state -of-the-art pre -trained models \n",
            "such as BERT (Bidirectional Encoder Representations from Transformers). \n",
            "These embeddings encode rich semantic representations of Telugu text, \n",
            "which significantly enhance the model ’s understanding of sentiment nuances.  \n",
            " \n",
            "7. Model Training and Validation:  Train the Bi -Directional LSTM model \n",
            "using the Sentiraama corpus, which contains 4abelled  Telugu reviews. \n",
            "Validate the model using a portion of the data to ensure its accuracy and \n",
            "generalization.  \n",
            " \n",
            "8. Evaluation:  Evaluate the trained model on a separate test set to assess its \n",
            "performance in real -world scenarios. Measure metrics such as accuracy, \n",
            "precision, recall, and F1 score.  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "4. Module -wise detailed discussion of the project: . \n",
            "Review – 1: \n",
            "In review -1, collected and processed Telugu product reviews using Sentiraama \n",
            "corpus. Tokenization and n -gram generation were employed for feature extraction, \n",
            "enhancing sentiment analysis. Text embeddings were generated using a pre -trained \n",
            "Telugu BERT model, aiding model training. Models like Random Forest and Logistic \n",
            "Regression are selected out of trained models and tuned for sentiment clas sification. \n",
            "Finally, the best -performing model was selected for predicting sentiment in new \n",
            "Telugu reviews, completing the sentiment analysis pipeline.  \n",
            "Accuracies of various models:  \n",
            "MACHINE LEARNING MODEL  ACCURACY  \n",
            "Decision Tree   50 %  \n",
            "Logistic Regression   75 %  \n",
            "SVC (Support Vector Classifier)   42 %  \n",
            "Random Forest  57 %  \n",
            "Naïve Bayes  57 %  \n",
            " \n",
            "Bi-Directional LSTM  \n",
            " \n",
            "1. Data Preprocessing:  The Telugu text undergoes tokenization to break it \n",
            "down into meaningful units. Subsequently, sequences are padded to ensure \n",
            "uniform length, and word embeddings are generated using pre -trained BERT \n",
            "models, capturing rich semantic information.  \n",
            "2. Model Architecture: The model comprises Bi -Directional LSTM layers with \n",
            "dropout regularization to prevent overfitting. This architecture allows the  \n",
            "model to capture contextual information from both past and future sequences, \n",
            "enhancing its understanding of Telugu reviews' sentiment.  \n",
            "3.Training Details:  \n",
            "Epochs:  Trained over 10 epochs, optimizing the learning process.  \n",
            "Training Accuracy:  Achieved 100% accuracy on the training data, indicating a \n",
            "strong ability to learn from the dataset.  \n",
            "Validation Accuracy:  Attained 80% accuracy on the validation set, indicating \n",
            "good generalization but showing signs of overfitting due to the large gap \n",
            "between training and validation accuracies.  \n",
            "4.Evaluation:  While the model performed well in terms of accuracy, the \n",
            "significant difference between training and validation accuracies suggests \n",
            "potential overfitting issues that need to be addressed.  \n",
            " \n",
            "LSTM Model  \n",
            "1.Data Preprocessing:  Similar to the Bi -Directional LSTM model, the Telugu \n",
            "text undergoes tokenization, padding for uniform length, and word embedding \n",
            "using pre -trained BERT models.  \n",
            "2.Model Architecture:  The LSTM model consists of LSTM layers with \n",
            "dropout regularization and dense layers for classification.  \n",
            "3.Training Details:  \n",
            "Epochs:  Trained over 20 epochs to optimize learning and model convergence.  \n",
            "Training Accuracy:  Achieved 51% accuracy on the training data, indicating \n",
            "moderate learning from the dataset.  \n",
            "Validation Accuracy:  Attained 47.5% accuracy on the validation set, which is \n",
            "lower compared to the Bi -Directional LSTM model, suggesting less effective \n",
            "performance.  \n",
            "4.Evaluation:  The LSTM model showed lower accuracy compared to the Bi -\n",
            "Directional LSTM, highlighting potential limitations in capturing the complexity \n",
            "of sentiment analysis in Telugu text.  \n",
            "  \n",
            " \n",
            "GRU Model  \n",
            " \n",
            "1.Data Preprocessing:  Similar preprocessing steps are applied, including \n",
            "tokenization, padding, and word embedding using pre -trained BERT models.  \n",
            "2.Model Architecture:  The GRU model comprises GRU layers with dropout \n",
            "and dense layers for classification.  \n",
            "3.Training Details:  \n",
            "Epochs:  Trained over 50 epochs, providing ample training iterations.  \n",
            "Training Accuracy:  Achieved 55% accuracy on the training data, indicating \n",
            "moderate learning but lower than the Bi -Directional LSTM model.  \n",
            "Validation Accuracy:  Attained 43.3% accuracy on the validation set, \n",
            "demonstrating the lowest accuracy among the models.  \n",
            "4.Evaluation:  The GRU model exhibited the lowest accuracy among the \n",
            "models, indicating limited effectiveness for sentiment analysis in Telugu text \n",
            "compared to LSTM and Bi -Directional LSTM models . \n",
            " \n",
            "5. Conclusion and future scope   \n",
            "Conclusion :  \n",
            " \n",
            "The Bi -Directional LSTM model achieved the highest training accuracy \n",
            "(100%) but showed signs of overfitting with a validation accuracy of 80%. This \n",
            "indicates a strong ability to learn from the training data but may not generalize \n",
            "well to unseen data.  \n",
            " \n",
            "The LSTM model, while showing lower overall accuracy, demonstrated more \n",
            "stable performance with less overfitting compared to the Bi -Directional LSTM \n",
            "model.  \n",
            "The GRU model exhibited the lowest accuracy among the models, suggesting \n",
            "limited effectiveness for sentiment analysis in Telugu text compared to LSTM \n",
            "and Bi -Directional LSTM models.  \n",
            " \n",
            "The LSTM model, with its balance between performance and generalization, \n",
            "appears to be the most suitable choice for sentiment analysis in Telugu text \n",
            "among the models evaluated.  \n",
            " \n",
            "By developing a system that analyzes Telugu reviews directly, it can bridge \n",
            "the gap between Telugu user feedback and product development efforts.  \n",
            "Enables Telugu speakers to provide feedback in their native language, leading \n",
            "to a more inclusive and user -friendly experience.  \n",
            "Provides companies with deeper insights into Telugu customer sentiment, \n",
            "allowing for targeted product improvements based on their specific needs and \n",
            "preferences.  \n",
            " \n",
            "Future scope :  \n",
            " \n",
            "This project lays the groundwork for a powerful suite of sentiment analysis \n",
            "tools tailored to the Telugu language and the electronic product domain. As \n",
            "the technology matures, the scope can broaden to encompass other product \n",
            "categories and eventually serve as a comprehensive platform for \n",
            "understanding customer sentiment across various industries within the \n",
            "Telugu -speaking market.  \n",
            "By continuously improving the accuracy and capabilities of the system, this \n",
            "project has the potential to bridge the communication gap between Telugu \n",
            "customers and businesses, fostering a more customer -centric approach to \n",
            "product development and ultimately leading to a more satisfying product \n",
            "experience for Telugu -speaking consumers.  \n"
          ]
        }
      ],
      "source": [
        "text = read_pdf('/content/demo.pdf')\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "u_GFyOTGPN_s"
      },
      "outputs": [],
      "source": [
        "def get_text_chunks(text):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(\n",
        "                  chunk_size=1000,\n",
        "                  chunk_overlap=200,\n",
        "                  length_function=len\n",
        "                  )\n",
        "  chunks = text_splitter.split_text(text=text)\n",
        "  return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHQBdoKKQTgr",
        "outputId": "35c2284e-8c4a-4afb-9885-44e7a8af1ba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['School of Computer Science and Engineering  \\n \\nSentiment analysis for Telugu  Reviews  \\nProject report s ubmitted to the partial fulfilment of the course  \\nCSI4001 – Natural Language Processing and Computational Linguistics  \\n \\n \\n \\n \\nProject report dated :  30-04-2024  \\n  \\n   \\n1. Project Objective  \\n \\nThe objective of this project is to develop a sentiment analysis system for \\nTelugu language,reviews of electronic products, categorizing them as positive \\n(1) or negative (0) by analyzing Telugu user opinions.  \\nThe goal is to understand sentiment towards electronic products in their \\nlanguage, aiding in product enhancement for improved customer satisfaction. \\nThis involves NLP tasks such as tokenization, N -gram analysis for word \\nsequences, utilizing BERT models for  contextual understanding, and word -to-\\nvector conversion to process Telugu text effectively and using some machine \\nlearning techniques and ,GRU , bidirectional LSTM,LSTM as models to train', \"vector conversion to process Telugu text effectively and using some machine \\nlearning techniques and ,GRU , bidirectional LSTM,LSTM as models to train \\nthe data on and check which is more accurate. Through these techniq ues, the \\nsystem aims to provide insights crucial for optimizing products based on \\nTelugu -speaking users' feedback.  \\n \\n2. Related works and Gap  \\nThe field of sentiment analysis, specially in languages with limited resources \\nlike Telugu, presents unique challenges due to the scarcity of annotated data, \\nlanguage -specific tools, and established research frameworks.  \\n \\nExisting work:  \\nA two -phase sentiment analysis for Telugu news sentences using Telugu \\nSentiWordNet. Initially, it identifies subjectivity classification, where each \\nsentence is classified as subjective or objective. Objective sentences are \\ntreated as neutral sentiment as they don't carry any sentiment value. Next, \\nsentiment classification is performed, where subjective sentences are further\", \"treated as neutral sentiment as they don't carry any sentiment value. Next, \\nsentiment classification is performed, where subjective sentences are further \\nclassified as positive or negative.This proposed system achieves an accuracy \\nof 74% and 81% for subjectivity and sentiment classificat ion, respectively.  \\n \\nWhile sentiment analysis exists for Telugu text, current systems typically \\nrequire English input, translating the meaning to Telugu for analysis. There's a \\nlack of models that directly accept Telugu user prompts, making this project a \\nnovel approach in thi s area.  \\n \\n \\n \\n \\n  \\nGaps Addressed:  \\n \\nNative Language Analysis:  This project focuses on analyzing Telugu \\nreviews directly, eliminating the need for translation and making the process \\nmore user -friendly for Telugu speakers.  \\nDeeper Product Insights:  By understanding sentiment in their native \\nlanguage, Telugu users can provide more refined feedback on electronic\", 'more user -friendly for Telugu speakers.  \\nDeeper Product Insights:  By understanding sentiment in their native \\nlanguage, Telugu users can provide more refined feedback on electronic \\nproducts. This allows companies to gain a deeper understanding of their \\nTelugu customer base and tailor product improvements to their specifi c needs \\nand preferences.  \\nIncreased Accessibility:  A Telugu sentiment analysis system empowers \\nTelugu speakers who may not be proficient in English to participate in product \\nreviews and have their voices heard. This can lead to a more inclusive \\nproduct development process.  \\n \\n \\n3. Proposed Solution to the Problem:  \\n \\n1.Methodology Overview:  The proposed solution involves leveraging Natural \\nLanguage Processing (NLP) techniques and machine learning models to \\nanalyze and classify Telugu text reviews. Key tasks include tokenization, N -\\ngram analysis, word embeddings, and model training using LSTM  (Long \\nShort -Term Memory) networks.', 'analyze and classify Telugu text reviews. Key tasks include tokenization, N -\\ngram analysis, word embeddings, and model training using LSTM  (Long \\nShort -Term Memory) networks.  \\n \\n2.Data collection:  The Sentiraama corpus is used for training data, which \\nincludes both positive and negative Telugu reviews.  \\n \\n3.Data Preprocessing:  The project begins with data preprocessing steps \\nsuch as text cleaning, punctuation removal, tokenization, and padding to \\nensure uniform input sequences for the machine learning models.  \\n \\n4.Tokenization : \\nTokenization is employed to break down Telugu text into individual tokens, \\ncapturing the semantic meaning and linguistic structure of the reviews.  \\n \\n \\n \\n  \\n5. , N -grams:  \\nN-grams analysis, including unigrams, bigrams, and trigrams, is utilized to \\nextract features that encompass both individual word context and broader \\ncontextual information within the reviews.  \\n \\n6.Text Embeddings:', 'extract features that encompass both individual word context and broader \\ncontextual information within the reviews.  \\n \\n6.Text Embeddings:  \\nText embeddings are generated using state -of-the-art pre -trained models \\nsuch as BERT (Bidirectional Encoder Representations from Transformers). \\nThese embeddings encode rich semantic representations of Telugu text, \\nwhich significantly enhance the model ’s understanding of sentiment nuances.  \\n \\n7. Model Training and Validation:  Train the Bi -Directional LSTM model \\nusing the Sentiraama corpus, which contains 4abelled  Telugu reviews. \\nValidate the model using a portion of the data to ensure its accuracy and \\ngeneralization.  \\n \\n8. Evaluation:  Evaluate the trained model on a separate test set to assess its \\nperformance in real -world scenarios. Measure metrics such as accuracy, \\nprecision, recall, and F1 score.  \\n \\n \\n \\n \\n \\n \\n \\n \\n4. Module -wise detailed discussion of the project: . \\nReview – 1:', 'performance in real -world scenarios. Measure metrics such as accuracy, \\nprecision, recall, and F1 score.  \\n \\n \\n \\n \\n \\n \\n \\n \\n4. Module -wise detailed discussion of the project: . \\nReview – 1: \\nIn review -1, collected and processed Telugu product reviews using Sentiraama \\ncorpus. Tokenization and n -gram generation were employed for feature extraction, \\nenhancing sentiment analysis. Text embeddings were generated using a pre -trained \\nTelugu BERT model, aiding model training. Models like Random Forest and Logistic \\nRegression are selected out of trained models and tuned for sentiment clas sification. \\nFinally, the best -performing model was selected for predicting sentiment in new \\nTelugu reviews, completing the sentiment analysis pipeline.  \\nAccuracies of various models:  \\nMACHINE LEARNING MODEL  ACCURACY  \\nDecision Tree   50 %  \\nLogistic Regression   75 %  \\nSVC (Support Vector Classifier)   42 %  \\nRandom Forest  57 %  \\nNaïve Bayes  57 %  \\n \\nBi-Directional LSTM', \"MACHINE LEARNING MODEL  ACCURACY  \\nDecision Tree   50 %  \\nLogistic Regression   75 %  \\nSVC (Support Vector Classifier)   42 %  \\nRandom Forest  57 %  \\nNaïve Bayes  57 %  \\n \\nBi-Directional LSTM  \\n \\n1. Data Preprocessing:  The Telugu text undergoes tokenization to break it \\ndown into meaningful units. Subsequently, sequences are padded to ensure \\nuniform length, and word embeddings are generated using pre -trained BERT \\nmodels, capturing rich semantic information.  \\n2. Model Architecture: The model comprises Bi -Directional LSTM layers with \\ndropout regularization to prevent overfitting. This architecture allows the  \\nmodel to capture contextual information from both past and future sequences, \\nenhancing its understanding of Telugu reviews' sentiment.  \\n3.Training Details:  \\nEpochs:  Trained over 10 epochs, optimizing the learning process.  \\nTraining Accuracy:  Achieved 100% accuracy on the training data, indicating a \\nstrong ability to learn from the dataset.\", 'Epochs:  Trained over 10 epochs, optimizing the learning process.  \\nTraining Accuracy:  Achieved 100% accuracy on the training data, indicating a \\nstrong ability to learn from the dataset.  \\nValidation Accuracy:  Attained 80% accuracy on the validation set, indicating \\ngood generalization but showing signs of overfitting due to the large gap \\nbetween training and validation accuracies.  \\n4.Evaluation:  While the model performed well in terms of accuracy, the \\nsignificant difference between training and validation accuracies suggests \\npotential overfitting issues that need to be addressed.  \\n \\nLSTM Model  \\n1.Data Preprocessing:  Similar to the Bi -Directional LSTM model, the Telugu \\ntext undergoes tokenization, padding for uniform length, and word embedding \\nusing pre -trained BERT models.  \\n2.Model Architecture:  The LSTM model consists of LSTM layers with \\ndropout regularization and dense layers for classification.  \\n3.Training Details:', 'using pre -trained BERT models.  \\n2.Model Architecture:  The LSTM model consists of LSTM layers with \\ndropout regularization and dense layers for classification.  \\n3.Training Details:  \\nEpochs:  Trained over 20 epochs to optimize learning and model convergence.  \\nTraining Accuracy:  Achieved 51% accuracy on the training data, indicating \\nmoderate learning from the dataset.  \\nValidation Accuracy:  Attained 47.5% accuracy on the validation set, which is \\nlower compared to the Bi -Directional LSTM model, suggesting less effective \\nperformance.  \\n4.Evaluation:  The LSTM model showed lower accuracy compared to the Bi -\\nDirectional LSTM, highlighting potential limitations in capturing the complexity \\nof sentiment analysis in Telugu text.  \\n  \\n \\nGRU Model  \\n \\n1.Data Preprocessing:  Similar preprocessing steps are applied, including \\ntokenization, padding, and word embedding using pre -trained BERT models.  \\n2.Model Architecture:  The GRU model comprises GRU layers with dropout', 'tokenization, padding, and word embedding using pre -trained BERT models.  \\n2.Model Architecture:  The GRU model comprises GRU layers with dropout \\nand dense layers for classification.  \\n3.Training Details:  \\nEpochs:  Trained over 50 epochs, providing ample training iterations.  \\nTraining Accuracy:  Achieved 55% accuracy on the training data, indicating \\nmoderate learning but lower than the Bi -Directional LSTM model.  \\nValidation Accuracy:  Attained 43.3% accuracy on the validation set, \\ndemonstrating the lowest accuracy among the models.  \\n4.Evaluation:  The GRU model exhibited the lowest accuracy among the \\nmodels, indicating limited effectiveness for sentiment analysis in Telugu text \\ncompared to LSTM and Bi -Directional LSTM models . \\n \\n5. Conclusion and future scope   \\nConclusion :  \\n \\nThe Bi -Directional LSTM model achieved the highest training accuracy \\n(100%) but showed signs of overfitting with a validation accuracy of 80%. This', 'Conclusion :  \\n \\nThe Bi -Directional LSTM model achieved the highest training accuracy \\n(100%) but showed signs of overfitting with a validation accuracy of 80%. This \\nindicates a strong ability to learn from the training data but may not generalize \\nwell to unseen data.  \\n \\nThe LSTM model, while showing lower overall accuracy, demonstrated more \\nstable performance with less overfitting compared to the Bi -Directional LSTM \\nmodel.  \\nThe GRU model exhibited the lowest accuracy among the models, suggesting \\nlimited effectiveness for sentiment analysis in Telugu text compared to LSTM \\nand Bi -Directional LSTM models.  \\n \\nThe LSTM model, with its balance between performance and generalization, \\nappears to be the most suitable choice for sentiment analysis in Telugu text \\namong the models evaluated.  \\n \\nBy developing a system that analyzes Telugu reviews directly, it can bridge \\nthe gap between Telugu user feedback and product development efforts.', 'among the models evaluated.  \\n \\nBy developing a system that analyzes Telugu reviews directly, it can bridge \\nthe gap between Telugu user feedback and product development efforts.  \\nEnables Telugu speakers to provide feedback in their native language, leading \\nto a more inclusive and user -friendly experience.  \\nProvides companies with deeper insights into Telugu customer sentiment, \\nallowing for targeted product improvements based on their specific needs and \\npreferences.  \\n \\nFuture scope :  \\n \\nThis project lays the groundwork for a powerful suite of sentiment analysis \\ntools tailored to the Telugu language and the electronic product domain. As \\nthe technology matures, the scope can broaden to encompass other product \\ncategories and eventually serve as a comprehensive platform for \\nunderstanding customer sentiment across various industries within the \\nTelugu -speaking market.  \\nBy continuously improving the accuracy and capabilities of the system, this', 'understanding customer sentiment across various industries within the \\nTelugu -speaking market.  \\nBy continuously improving the accuracy and capabilities of the system, this \\nproject has the potential to bridge the communication gap between Telugu \\ncustomers and businesses, fostering a more customer -centric approach to \\nproduct development and ultimately leading to a more satisfying product \\nexperience for Telugu -speaking consumers.']\n"
          ]
        }
      ],
      "source": [
        "text_chunks = get_text_chunks(text)\n",
        "print(text_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aekt8mbmPRg7"
      },
      "outputs": [],
      "source": [
        "def get_vector_store(text_chunks):\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
        "    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)\n",
        "    vector_store.save_local(\"faiss_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "YqDgTXsCUGyy"
      },
      "outputs": [],
      "source": [
        "get_vector_store(text_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "43Xpg_gQRSeN"
      },
      "outputs": [],
      "source": [
        "def get_conversational_chain():\n",
        "    prompt_template = \"\"\"\n",
        "    Answer the question using the relevant context provided below.\n",
        "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "    Context:\\n {context}?\\n\n",
        "    Question: \\n{question}\\n\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "    model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3)\n",
        "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "    chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
        "    return chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QXL05_zGTiUD"
      },
      "outputs": [],
      "source": [
        "def user_input(user_question):\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "    new_db = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
        "    docs = new_db.similarity_search(user_question)\n",
        "    chain = get_conversational_chain()\n",
        "    response = chain({\"input_documents\": docs, \"question\": user_question}, return_only_outputs=True)\n",
        "    print(\"Reply:\", response[\"output_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DKb0YCllTmxK"
      },
      "outputs": [],
      "source": [
        "user_question = \"what is the objective of the project?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmXjUKQGU5wZ",
        "outputId": "7ad661e7-b60e-4d85-917d-73163a83feef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reply: The objective of this project is to develop a sentiment analysis system for Telugu language,reviews of electronic products, categorizing them as positive (1) or negative (0) by analyzing Telugu user opinions.\n"
          ]
        }
      ],
      "source": [
        "user_input(user_question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqAnJMsHVAjY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
